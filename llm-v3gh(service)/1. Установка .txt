# Установка текстового AI-ассистента по SSH

Это руководство поможет вам установить и запустить текстовый AI-ассистент на вашем сервере через SSH.

## Предварительные требования
- Сервер с доступом по SSH
- Установленный Python 3
- Доступ к интернету для загрузки зависимостей и модели

## Инструкция по установке

1. **Создание структуры папок приложения**
   ```bash
   mkdir -p llm-pre/{templates,static} && cd llm-pre
   ```

2. **Создание и активация виртуального окружения**
   ```bash
   python3 -m venv venv && source venv/bin/activate
   ```

3. **Установка необходимых зависимостей**
   ```bash
   pip install fastapi uvicorn llama-cpp-python
   ```
   *или используйте файл requirements.txt, если он есть*

4. **Установка модели**
   ```bash
   wget https://huggingface.co/IlyaGusev/saiga_yandexgpt_8b_gguf/resolve/main/saiga_yandexgpt_8b.Q3_K_M.gguf
   ```

5. **Создание файла приложения**
   ```bash
   sudo nano chatbot_web.py
   ```
   - Вставьте содержимое файла приложения
   - Проверьте название модели в коде
   - Сохраните (Ctrl+S) и закройте (Ctrl+X)

6. **Создание файла веб-интерфейса**
   ```bash
   sudo nano templates/index.html
   ```
   - Вставьте содержимое HTML-файла
   - Сохраните (Ctrl+S) и закройте (Ctrl+X)

7. **Загрузка модели (если не выполнено на шаге 4)**
   ```bash
   wget https://huggingface.co/IlyaGusev/saiga_yandexgpt_8b_gguf/resolve/main/saiga_yandexgpt_8b.Q3_K_M.gguf
   ```

## Запуск приложения

1. **Старт приложения**
   ```bash
   python chatbot_web.py
   ```

2. **Доступ к пользовательскому интерфейсу**
   Откройте в браузере:
   ```
   http://localhost:8000
   ```

## Примечания
- Убедитесь, что порт 8000 открыт в настройках вашего сервера
- Для работы в фоновом режиме рассмотрите использование `screen` или `tmux`
- Модель требует значительных ресурсов, убедитесь, что ваш сервер имеет достаточную производительность